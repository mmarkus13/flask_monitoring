{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BMW Flask API installation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "update bashrc for qq user:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run once:\n",
    "\n",
    "cleantext=\"\n",
    "export HISTTIMEFORMAT=\"[%Y-%m-%d %H:%M:%S] \"\n",
    "HISTSIZE='INFINITY'; HISTFILESIZE='ANDBEYOND'\n",
    "\n",
    "PS1='\\e[37m\\D{%H:%M}\\e[91m[\\e[90m\\u@\\h \\e[33m\\w\\e[31m]\\e[92m\\n\\$'\n",
    "\n",
    "alias ll='ls -alF'\n",
    "alias la='ls -A'\n",
    "alias l='ls -CmF'\n",
    "alias lr='ls -ltrh'\n",
    "alias ufind=\"find / -name $1 2>/dev/null\"\n",
    "\n",
    "export PATH=$PATH:/home/${USER}/scripts\n",
    "\"\n",
    "\n",
    "echo \"$cleantext\" >> /home/${USER}/.bashrc.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check OS vesion:\n",
    "cat /etc/os-release"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(below commands are for RHEL distro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install prereqs with elevated user:\n",
    "\n",
    "# prod:\n",
    "yum install -y libXcomposite libXcursor libXi libXtst libXrandr alsa-lib mesa-libEGL libXdamage mesa-libGL libXScrnSaver bc\n",
    "\n",
    "# dev:\n",
    "subscription-manager repos --enable=codeready-builder-for-rhel-8-x86_64-rpms # required for x11\n",
    "yum install -y libXcomposite libXcursor libXi libXtst libXrandr alsa-lib mesa-libEGL libXdamage mesa-libGL libXScrnSaver bc xorg-x11-apps xorg-x11-xauth firefox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Within VDI]\n",
    "> download <mark>Anaconda3-2020.02-Linux-x86_64.sh</mark> from https://repo.anaconda.com/archive/ \n",
    "\n",
    "> download & install WinSCP from http://wuss.bmwgroup.net\n",
    "\n",
    "> upload Anaconda3-2020.02-Linux-x86_64.sh to <mark>Telegraf host</mark> to /tmp or /home/qqky020/UI/install_files (but first create the folder for that - see below)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Telegraf host]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create folders:\n",
    "mkdir -p  /home/${USER}/UI/Flask ~/UI/install_files\n",
    "# give execute rights to the installed:\n",
    "chmod +x Anaconda3-2020.02-Linux-x86_64.sh\n",
    "# Long press Enter; then \"yes\"; then \"yes\" (again)\n",
    "# when completed - reload shell:\n",
    ". ~/.bashrc\n",
    "# install requirements for Flask API (maybe you need to update the path to requirements folder: check \"flask_wapi_UAT\")\n",
    "cd  ~/UI/flask_wapi_UAT/requirements; `for': for file in $(ls) ; do pip install ./${file}; done  \n",
    "    # check if all are required (wheel; tar.gz.. some might be duplicates)\n",
    ". ../.flaskenv\n",
    ". ../.flask run\n",
    "# dev/test instance\n",
    "flask run --host 0.0.0.0  \n",
    "# prod\n",
    "IP=\"$(hostname -I | awk '{print $1}')\"\n",
    "nohup flask run --host $IP &\n",
    "# to close it type \"fg\" and press ctrl+c; #or \"kill %1\" #but be sure that is the only background process that is running!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[VDI]\n",
    "> open preferred web browser\n",
    "\n",
    "> open the UI: http://<mark>XX.X.XX.XX</mark>:8000 #replace with correct IP address <mark># note that the firewall port 8000 has to be opened!</mark>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Telegraf host]\n",
    "\n",
    "Backend & <b>cronjobs</b>: <mark>monitoring_services.sh</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create backend script:\n",
    "vi monitoring_services.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### paste the below // current version = v1.04; 2022.08.12 (Author: Michal Márkus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash -x\n",
    "# monitoring_services.sh\n",
    "\n",
    "\n",
    "# TIMER -start\n",
    "res1=$(date +%s.%N)\n",
    "# measure runtime of this script\n",
    "\n",
    "DATE=`date +'%m/%d/%Y %H:%M:%S'`\n",
    "err_msg=\"not running @$DATE\"\n",
    "ok_msg=\"OK @$DATE\"\n",
    "\n",
    "flask_path=/home/qqky020/UI/flask_wapi_UAT\n",
    "cd $flask_path\n",
    "\n",
    "\n",
    "\n",
    "# Define function to check service status:\n",
    "services_check()\n",
    "{\n",
    "\n",
    "# ACTIVE_IQ\n",
    "    # not defined yet\n",
    "    \n",
    "# GRAFANA:\n",
    "    grafana_status()\n",
    "    {\n",
    "        #grafana_url=\"https://grafana.apps.kynprodocp.bmwgroup.net/api/health\"  # PROD (port is 443)\n",
    "        grafana_url=\"http://itahdnasrep.bmwgroup.net:3000/api/health\"  # UAT\n",
    "        grafana_check=\"$(curl -s $grafana_url | grep -oh [[:alpha:]]*ok[[:alpha:]]*)\"  # checks if status is \"ok\"\n",
    "        grafana_latency=$(curl -s -w 'Establish Connection: %{time_connect}s\\nTTFB: %{time_starttransfer}s\\nTotal: %{time_total}s\\n' itahdnasrep.bmwgroup.net:3000/ping/api/health | egrep \"Total: [1-9]\") ;  # checks if latency is above 1 second\n",
    "        # log status:\n",
    "        [ $(eval echo \\$\"${service}_check\") == 'ok' ] && [ -z \"$latency\" ] || echo -e \"\\n$DATE\\n$grafana_check\\n\\n###\" >> ${service}_high_latency.log && echo \"${service} $ok_msg\" >> ${service}_uptime.log || echo \"${service}\" $err_msg >> ${service}_uptime.log\n",
    "        export grafana_latency\n",
    "    }\n",
    "\n",
    "# HARVEST:\n",
    "\n",
    "# QQ USER NEEDS TO BE ADDED TO REMOTE HOST & set up PWLESS SSH (or info needs to be posted to this host via Ansible...)\n",
    "    harvest_status()\n",
    "    {\n",
    "        harvest_check=\"$(ssh -tt michal@itahdnasuathar.bmwgroup.net 'systemctl status harvest')\"  # to be replaced with qq user!\n",
    "        if [ \"$(eval echo \\$${service}_check) | sort -u | grep -v running | wc -l)\" -gt 0 ]; then echo \"${service}\" $err_msg  >> ${service}_uptime.log; else echo \"${service} $ok_msg\";fi\n",
    "    }\n",
    "\n",
    "# INFLUX:\n",
    "    influx_status()\n",
    "    {\n",
    "        #influx_url=\"https://influxdb.apps.kynprodocp.bmwgroup.net/health\"  # PROD (port is 443)\n",
    "        influx_url=\"http://itahdnasrep.bmwgroup.net:8086/health\"  # UAT\n",
    "        influx_check=\"$(curl -s $influx_url | grep status |  grep -oh [[:alpha:]]*pass[[:alpha:]]*)\"  # check if status is \"pass\"\n",
    "        influx_latency=$(curl -s -w 'Establish Connection: %{time_connect}s\\nTTFB: %{time_starttransfer}s\\nTotal: %{time_total}s\\n' itahdnasrep.bmwgroup.net:8086 | egrep \"Total: [1-9]\")\n",
    "        [ $(eval echo \\$\"${service}_check\") == 'pass' ] && [ -z \"$latency\" ] || echo -e \"\\n$DATE\\n${service}_check\\n\\n###\" >> ${service}_high_latency.log && echo \"${service} $ok_msg\" >> ${service}_uptime.log || echo \"${service}\" $err_msg  >> ${service}_uptime.log\n",
    "        export influx_latency\n",
    "    }\n",
    "\n",
    "# NodeRed\n",
    "    # not defined yet\n",
    "\n",
    "# TELEGRAF:\n",
    "    telegraf_status()\n",
    "    {\n",
    "        telegraf_check=\"$(systemctl | grep telegraf | sort -u | grep -v running | wc -l)\"\n",
    "        if ! [ \"$(echo $telegraf_check)\" == 0 ]; then echo \"${service}\" $err_msg >> ${service}_uptime.log; else echo \"${service} $ok_msg\" >> ${service}_uptime.log; fi\n",
    "        export telegraf_check\n",
    "    }\n",
    "\n",
    "# LOOP OVER SERVICES:\n",
    "for service in grafana influx telegraf #active_iq harvest nodered\n",
    "    do\n",
    "        ${service}_status\n",
    "    done\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# send ticket if service is down for 5 consecutive minutes\n",
    "ticket()\n",
    "{\n",
    "\n",
    "# ticket details:\n",
    "if\n",
    "    service=grafana; then\n",
    "    eventID=\"123456...\"\n",
    "    resource=\"itahdnasrep\"  # UAT\n",
    "    #state=$(serviceup5min || echo  \"OK\")\n",
    "    state=$grafana_check\n",
    "    latency=$grafana_latency\n",
    "    severity=\"1\"\n",
    "    header=\"Date, Service, Status, EventID, Resource, Severity\"\n",
    "    message=\"$DATE, $service; $state; $eventID, $resource, $severtiy\"\n",
    "elif\n",
    "    service=influx; then\n",
    "    eventID=\"123456...\"\n",
    "    resource=\"itahdnasrep\"  # UAT\n",
    "    state=$influx_check\n",
    "    latency=$influx_latency\n",
    "    severity=\"1\"\n",
    "    header=\"Date, Service, Status, EventID, Resource, Severity\"\n",
    "    message=\"$DATE, $service; $state; $eventID, $resource, $severtiy\"\n",
    "elif\n",
    "    service=telegraf; then\n",
    "    eventID=\"123456...\"\n",
    "    resource=\"itahdnasrep\"  # UAT\n",
    "    state=$telegraf_check\n",
    "    #telegraf_jobs=\"$telegraf_check\"\n",
    "    severity=\"1\"\n",
    "    header=\"Date, Service, Status, EventID, Resource, Severity\"\n",
    "    message=\"$DATE, $service; $state; $eventID, $resource, $severtiy\"\n",
    "    #...\n",
    "fi\n",
    "\n",
    "    \n",
    "EPOCHNOW=`date -d \"${DATE}\" +\"%s\"`\n",
    "    # Send info to NodeRed when service is down:\n",
    "    serviceup5min()    \n",
    "        {\n",
    "        c=0\n",
    "        for((i=1;i<=5;++i))\n",
    "            do\n",
    "            stat=$(tac ${service}_uptime.log | sed -n \"${i},1p\")\n",
    "            dat=$(echo $stat| cut -d@ -f2)\n",
    "                case $stat in\n",
    "                OK) return 1 ;;\n",
    "                not)\n",
    "                epoch_dat=`date -d \"${dat}\" +\"%s\"`\n",
    "                    if [ \"$(echo $EPOCHNOW-$epoch_dat|bc)\" -le \"360\"  ] # less or equal to 360 seconds AKA 6 min (5min +1min grace time due to latency)\n",
    "                    then c=$((c+1))\n",
    "                    export c\n",
    "                    # if [ \"$c\" == 1 ]; then echo ${service}_down_since \"$epoch_dat\"; fi\n",
    "                fi ;;\n",
    "                esac\n",
    "            done\n",
    "        }\n",
    " \n",
    "    \n",
    "    create_ticket()\n",
    "        {\n",
    "            file=${service}_monitoring_ticket_`date +\\%Y\\%m\\%d\\%H\\%M`.json\n",
    "            if [[ $c -ge 5 ]]; then echo -e \"$header\"\\n\"$message\" > $file; else echo $DATE $service - OK; fi\n",
    "        }\n",
    "\n",
    "    for service in grafana influx telegraf #harvest #ansible nodered\n",
    "        do\n",
    "            serviceup5min && create_ticket\n",
    "        done \n",
    "    }\n",
    "\n",
    "\n",
    "    send_ticket()\n",
    "        {\n",
    "        # POST json TO NODERED    \n",
    "        }\n",
    "\n",
    "    #send_ticket\n",
    "\n",
    "\n",
    "\n",
    "manage_logs()\n",
    "    {\n",
    "        servce_uptime()\n",
    "        {\n",
    "            tac ${service}_uptime.log | grep -A1 -m 1 \"not\"  | tail -1 > ${service}_up_since.txt\n",
    "        }\n",
    "\n",
    "        for service in grafana influx telegraf #.....\n",
    "            do\n",
    "                servce_uptime\n",
    "            done\n",
    "\n",
    "        past_incidents()\n",
    "        {\n",
    "            for T in DAYS WEEKS MONTH;\n",
    "            do declare t=${T,,}; #echo $t;\n",
    "                RANGE=$(date -d \"$date -1 ${t}\" +\"%s\");\n",
    "\n",
    "                #cat telegraf_uptime.log | while read line;\n",
    "                ls *_uptime.log | xargs cat | grep -v OK | sort -u | while read line;\n",
    "                do\n",
    "                    x=$(echo $line |cut -d@ -f2)\n",
    "                    # if x is number number then convert to epoch format (y):\n",
    "                    #if [[ $x == ?(-)+([0-9])  ]]; then  # x is NOT a number because \"/\" characters in time format!...\n",
    "                    if ! [[ $x == '' ]]; then\n",
    "                        y=$(date -d \"$x\" +\"%s\")  # && echo $y-$RANGE|bc;  # check difference\n",
    "                        if [ \"$RANGE\" -le \"$y\" ]; then  echo $line >> incidents_${t}.csv; fi\n",
    "                    fi\n",
    "                done\n",
    "            done\n",
    "\n",
    "        # add when it was restarted started//since when it is running, and how long it runs; was down\n",
    "        # can calculate uptime from last difference\n",
    "\n",
    "        mv incidents_days.csv today.csv 2>/dev/null\n",
    "        mv incidents_weeks.csv weekly.csv 2>/dev/null\n",
    "        mv incidents_month.csv montly.csv 2>/dev/null\n",
    "    }\n",
    "\n",
    "    # call past incidents subfunction\n",
    "    past_incidents\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "# Run main parts of the script:\n",
    "services_check\n",
    "ticket\n",
    "manage_logs\n",
    "\n",
    "\n",
    "# TIMER STOP (calculate runtime):\n",
    "res2=$(date +%s.%N)\n",
    "dt=$(echo \"$res2 - $res1\" | bc)\n",
    "dd=$(echo \"$dt/86400\" | bc)\n",
    "dt2=$(echo \"$dt-86400*$dd\" | bc)\n",
    "dh=$(echo \"$dt2/3600\" | bc)\n",
    "dt3=$(echo \"$dt2-3600*$dh\" | bc)\n",
    "dm=$(echo \"$dt3/60\" | bc)\n",
    "ds=$(echo \"$dt3-60*$dm\" | bc)\n",
    "\n",
    "printf \"script run for: %d:%02d:%02d:%02.4f\\n\" $dd $dh $dm $ds\n",
    "echo\n",
    "\n",
    "exit 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit the crontab via:\n",
    "crontab -e\n",
    "# paste the following (this script runs every minute):\n",
    "*/1 * * * * source ~/.bashrc; /home/qq_XX/monitoring_services.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2022.08.05: STATUS for P1: `72% #progress`\n",
    "\n",
    "### P1 (pending items):\n",
    "\n",
    "> <b>monitoring_services.sh</b> `[1,5%]`: generate_report() --json part; <b>UI</b>: \n",
    "\n",
    "> 'Past Incidents' tab: add uptime `[5%]`\n",
    "\n",
    "> Enable passwordless ssh for qq user; or copy required files ('systemctl status harvest' output; maintenance.csv [resource,service,start,end] from NodeRed to telegraf host) `[5%]`\n",
    "\n",
    "> Maintenance mode `[10%]` ; check Active IQ export; update monitoring_services.sh & UI (*check_service.py subprocesses) for maintenance\n",
    "\n",
    "\n",
    "> `+15% extra` <mark>UPTIME</mark> reporting via `curl` or telegraf plugin... \n",
    "\n",
    "#### P1 completed items:\n",
    "> Check/debug: <b>monitoring_services.sh</b> `[1,5%]` @2022.08.09\n",
    "\n",
    "> infra.html ` [2%]` @2022.08.09\n",
    "\n",
    "#### P2 plan:\n",
    "- Ansible jobs \n",
    "- Performance metrics/alerts/jobs...\n",
    "- Add http<mark>s</mark> & cert to flask\n",
    "\n",
    "#### P3 plan:\n",
    "- CSS formatting\n",
    "- Check redundant packages at <mark>requirements</mark> & check which modules are being used, so that on prod we don't have to install anaconda (minimalistic approach)\n",
    "- Configure <mark>X11</mark> for jupyter on telegraf host"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decommission:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rm -rf ~/anaconda3  # also remove anaconda stuff from ~/.bashrc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tool configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Telegraf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Info from Florian:\n",
    "---\n",
    "```\n",
    "I prepared the Grid configuration already, so that the Telegraf can start to collect the data. \n",
    "Please take care that it can take up to 15 minutes with the initial data collection till it get reflected into the InfluxDB with the “prometheus” _measurements. \n",
    "\n",
    "StorageGRID requires a certificate authentication, so in addition I attached you the required certificates. \n",
    "Move them in the /etc/telegraf directory or subdirectory (modify tls_ca/tls_ca_cert & tls_key path in this case).\n",
    "\n",
    "There are 3 configuration parts to be modified / checked. \n",
    "\n",
    "#1  modify the common Telegraf config (at the beginning of the config file)\n",
    "[agent]\n",
    "   interval = “60s”\n",
    "   metric_batch_size = 5000\n",
    "   metric_buffer_limit = 75000\n",
    "\n",
    "\n",
    "#2  add the Storagegrid Input config\n",
    " [[inputs.prometheus]] \n",
    "   urls = ['https://10.2.62.68:9091/federate?match%5B%5D=%7Bjob%3D~%22.%2B%22%7D']\n",
    "   metric_version = 2\n",
    "   tls_ca = \"/etc/telegraf/cacert.pem\"\n",
    "   tls_cert = \"/etc/telegraf/cert.pem\"\n",
    "   tls_key = \"/etc/telegraf/key.pem\"\n",
    "   insecure_skip_verify = true\n",
    "   response_timeout = \"59s\"\n",
    "\n",
    "\n",
    "#3 check your [outputs.influxdb_v2]] configuration. \n",
    "Telegraf will write the data into the according bucket you set here. \n",
    "\n",
    "\n",
    "After this restart the Telegraf (via cmd # sudo systemctl stop telegraf & # sudo systemctl start telegraf). \n",
    "15 Minutes after this, the InfluxDB will reflect the StorageGRID data.\n",
    "``` \n",
    "\n",
    "> Source: mail @Fri 22/05/13 13:11\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UAT Telegraf config steps\n",
    "Telegraf configuration\n",
    "Telegraf agents located on: <b>ITAHDNASUATTEL</b>\n",
    "There is 5 instance running\n",
    "- SNMP trap receiver\n",
    "- SNMP query for Cisco Switches\n",
    "- VM server data receiver\n",
    "installation folder:\n",
    "`/etc/telegraf`\n",
    "each telegraf has its own service\n",
    "#### sytemctl status telegraf_broadcom.service\n",
    "`/usr/bin/telegraf -config /etc/telegraf/telegraf_broadcom.conf -config-directory /etc/telegraf/telegraf_broadcom`\n",
    "#### sytemctl status telegraf_cisco.service\n",
    "`/usr/bin/telegraf -config /etc/telegraf/telegraf_cisco.conf -config-directory /etc/telegraf/telegraf_cisco`\n",
    "#### sytemctl status telegraf_storage.service \n",
    "`/usr/bin/telegraf -config /etc/telegraf/telegraf_storage.conf -config-directory /etc/telegraf/telegraf_storage`\n",
    "#### sytemctl status telegraf_traps.service\n",
    "`/usr/bin/telegraf -config /etc/telegraf/telegraf_traps.conf -config-directory /etc/telegraf/telegraf_traps`\n",
    "#### sytemctl status telegraf_system.service\n",
    "`/usr/bin/telegraf -config /etc/telegraf/telegraf_system.conf -config-directory /etc/telegraf/telegraf_system`\n",
    "\n",
    "To receive SNMP traps from AIQ UM two MIB file required to copied to the configured path where the MIB's name are important\n",
    "- NETAPP.MIB\n",
    "- OCUM.MIB (this is a renamed aiqum_9.9.mib)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Influx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Influx CLI and Modify <mark>bucket's retention</mark>\n",
    "Install Influx CLI/Modify bucket's retention:\n",
    "Download package from the following URL: https://docs.influxdata.com/influxdb/cloud/tools/influx-cli/?t=Windows\n",
    "Install CLI to VDI: Because we haven't permission on the 'C:\\Program Files' folder, need modify the original command:\n",
    "Ori: Expand-Archive .\\influxdb2-client-2.3.0-windows-amd64.zip -DestinationPath 'C:\\Program Files\\InfluxData' mv 'C:\\Program Files\\InfluxData\\influxdb2-client-2.3.0-windows-amd64' 'C:\\Program Files\\InfluxData\\influx'\n",
    "Modified: Expand-Archive .\\influxdb2-client-2.3.0-windows-amd64.zip -DestinationPath 'C:\\InfluxData' mv 'C:\\InfluxData\\influxdb2-client-2.3.0-windows-amd64' 'C:\\InfluxData\\influx'\n",
    "Use Powershell for the following\n",
    "Before issuing the above command, navigate to the folder where you downloaded the CLI package. For example:\n",
    "```\n",
    "cd C:\\Users\"USERNAME\"\\Downloads`\n",
    "mkdir C:\\InfluxData`\n",
    "Expand-Archive .\\influxdb2-client-2.3.0-windows-amd64.zip -DestinationPath 'C:\\InfluxData'\n",
    "mv 'C:\\InfluxData\\influxdb2-client-2.3.0-windows-amd64' 'C:\\InfluxData\\influx'\n",
    "Navigate to the C:\\InfluxData\\influx // because we cannot modify the 'path' variable, need to go to the folder where the influx.exe exists\n",
    "Create an influx CLI's config for the remote host: .\\influx config create -a -n CONFIGNAME -u URL -t TOKEN_WHICH_HAS_PROPER_PRIVILEGES -o ORGANIZATION\n",
    "List bucket's current settings:\n",
    "PS C:\\InfluxData\\influx> .\\influx.exe bucket list ID Name Retention Shard group duration Organization ID Schema Type 834ba3f797c35789 BroadcomBES 1440h0m0s 24h0m0s f24c8a8d0e5f36e8 implicit f827bf73e326118b CiscoBackend 1440h0m0s 24h0m0s f24c8a8d0e5f36e8 implicit\n",
    "Modify bucket's retention: Command reference: https://docs.influxdata.com/influxdb/v2.2/organizations/buckets/update-bucket/\n",
    ".\\influx bucket update -i BUCKET_ID -r NEW_RETENTION_TIME\n",
    "```\n",
    "Done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
