{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BMW Flask API installation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "update bashrc for qq user:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run once:\n",
    "\n",
    "cleantext=\"\n",
    "export HISTTIMEFORMAT=\"[%Y-%m-%d %H:%M:%S] \"\n",
    "HISTSIZE='INFINITY'; HISTFILESIZE='ANDBEYOND'\n",
    "\n",
    "PS1='\\e[37m\\D{%H:%M}\\e[91m[\\e[90m\\u@\\h \\e[33m\\w\\e[31m]\\e[92m\\n\\$'\n",
    "\n",
    "alias ll='ls -alF'\n",
    "alias la='ls -A'\n",
    "alias l='ls -CmF'\n",
    "alias lr='ls -ltrh'\n",
    "alias ufind=\"find / -name $1 2>/dev/null\"\n",
    "\n",
    "export PATH=$PATH:/home/${USER}/scripts  # currently not used\n",
    "\"\n",
    "\n",
    "echo \"$cleantext\" >> /home/${USER}/.bashrc.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check OS vesion:\n",
    "cat /etc/os-release"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(below commands are for RHEL distro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install prereqs with elevated user:\n",
    "\n",
    "# prod:\n",
    "yum install -y libXcomposite libXcursor libXi libXtst libXrandr alsa-lib mesa-libEGL libXdamage mesa-libGL libXScrnSaver\n",
    "\n",
    "# dev:\n",
    "subscription-manager repos --enable=codeready-builder-for-rhel-8-x86_64-rpms # required for x11\n",
    "yum install -y libXcomposite libXcursor libXi libXtst libXrandr alsa-lib mesa-libEGL libXdamage mesa-libGL libXScrnSaver xorg-x11-apps xorg-x11-xauth firefox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Within VDI]\n",
    "> download <mark>Anaconda3-2020.02-Linux-x86_64.sh</mark> from https://repo.anaconda.com/archive/ \n",
    "\n",
    "> download & install WinSCP from http://wuss.bmwgroup.net\n",
    "\n",
    "> upload Anaconda3-2020.02-Linux-x86_64.sh to <mark>Telegraf host</mark> to /tmp or /home/qqky020/UI/install_files (but first create the folder for that - see below)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Telegraf host]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create folders:\n",
    "mkdir -p  /home/${USER}/UI/Flask ~/UI/install_files\n",
    "# give execute rights to the installed:\n",
    "chmod +x Anaconda3-2020.02-Linux-x86_64.sh\n",
    "# Long press Enter; then \"yes\"; then \"yes\" (again)\n",
    "# when completed - reload shell:\n",
    ". ~/.bashrc\n",
    "# install requirements for Flask API (maybe you need to update the path to requirements folder: check \"flask_wapi_UAT\")\n",
    "cd  ~/UI/flask_wapi_UAT/requirements; `for': for file in $(ls) ; do pip install ./${file}; done  \n",
    "    # check if all are required (wheel; tar.gz.. some might be duplicates)\n",
    ". ../.flask run\n",
    "# dev/test instance\n",
    "flask run --host 0.0.0.0  \n",
    "# prod\n",
    "IP=\"$(hostname -I | awk '{print $1}')\"\n",
    "nohup flask run --host $IP &\n",
    "# to close it type \"fg\" and press ctrl+c; #or \"kill %1\" #but be sure that is the only background process that is running!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[VDI]\n",
    "> open preferred web browser\n",
    "\n",
    "> open the UI: http://<mark>XX.X.XX.XX</mark>:8000 #replace with correct IP address <mark># note that the firewall port 8000 has to be opened!</mark>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Telegraf host]\n",
    "\n",
    "Backend & <b>cronjobs</b>: <mark>monitoring_services.sh</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create backend script:\n",
    "vi monitoring_services.sh\n",
    "# paste the below (to be updated) #current version = v1.05; 2022.08.05 (Author: Michal Márkus)\n",
    "########################################################################################\n",
    "\n",
    "#!/bin/bash\n",
    "#-x\n",
    "# monitoring_services.sh\n",
    "\n",
    "\n",
    "DATE=`date +'%m/%d/%Y %H:%M:%S'`\n",
    "err_msg=\"not running @\"\n",
    "\n",
    "flask_path=/home/qqky020/UI/flask_wapi_UAT\n",
    "cd $flask_path\n",
    "\n",
    "\n",
    "services_check()\n",
    "{\n",
    "\n",
    "# Check status if services are running:\n",
    "\n",
    "\n",
    "# GRAFANA:\n",
    "        grafana_status()\n",
    "        {\n",
    "                grafana_check=\"$(curl -sL -I itahdnasrep.bmwgroup.net:3000/ping/api/health | grep HTTP | grep 200 | awk '{print $2}')\";  # echo \"$grafana_check\"\n",
    "                grafana_latency=$(curl -s -w 'Establish Connection: %{time_connect}s\\nTTFB: %{time_starttransfer}s\\nTotal: %{time_total}s\\n' itahdnasrep.bmwgroup.net:3000/ping/api/health | egrep \"Total: [1-9]\");  # echo $grafana_latency  # test with 0\n",
    "                [ $(eval echo \\$\"${service}_check\") == 200 ] && [ -z \"$latency\" ] || echo -e \"\\n$DATE\\n$grafana_check\\n\\n###\" >> ${service}_high_latency.log && echo \"${service} OK\" >> ${service}_uptime.log || echo \"${service}\" $err_msg $DATE >> ${service}_uptime.log\n",
    "        }\n",
    "\n",
    "\n",
    "# HARVEST:\n",
    "\n",
    "# QQ USER NEEDS TO BE ADDED TO REMOTE HOST & set up PWLESS SSH (or info needs to be posted to this host via Ansible...)\n",
    "\n",
    "\n",
    "        harvest_status()\n",
    "        {\n",
    "                harvest_check=\"$(ssh -tt michal@itahdnasuathar.bmwgroup.net 'systemctl status harvest')\"  # to be replaced with qq user!\n",
    "                if [ \"$(eval echo \\$${service}_check) | sort -u | grep -v running | wc -l)\" -gt 0 ]; then echo \"${service}\" $err_msg $DATE >> ${service}_uptime.log; else echo \"${service} OK\";fi\n",
    "        }\n",
    "\n",
    "\n",
    "# INFLUX:\n",
    "        influx_status()\n",
    "        {\n",
    "                influx_check=\"$(curl -sL -I itahdnasrep.bmwgroup.net:8086 | grep HTTP | grep 200 | awk '{print $2}')\"\n",
    "                influx_latency=$(curl -s -w 'Establish Connection: %{time_connect}s\\nTTFB: %{time_starttransfer}s\\nTotal: %{time_total}s\\n' itahdnasrep.bmwgroup.net:8086 | egrep \"Total: [3-9]\")  # test with 0\n",
    "                [ $(eval echo \\$\"${service}_check\") == 200 ] && [ -z \"$latency\" ] || echo -e \"\\n$DATE\\n${service}_check\\n\\n###\" >> ${service}_high_latency.log && echo \"${service} OK\" >> ${service}_uptime.log || echo \"${service}\" $err_msg $DATE >> ${service}_uptime.log\n",
    "        }\n",
    "\n",
    "\n",
    "###\n",
    "\n",
    "#declare {nodered,ansible}=\"echo not configured yet \"  # CURRENTLY NOT SET\n",
    "\n",
    "###\n",
    "\n",
    "\n",
    "# TELEGRAF:\n",
    "\n",
    "        telegraf_status()\n",
    "        {\n",
    "                telegraf_check=\"$(systemctl | grep telegraf | sort -u | grep -v running | wc -l)\"\n",
    "                if ! [ \"$(echo $telegraf_check)\" == 0 ]; then echo \"${service}\" $err_msg$DATE >> ${service}_uptime.log; else echo \"${service} OK\" >> ${service}_uptime.log; fi\n",
    "        }\n",
    "\n",
    "\n",
    "# LOOP OVER SERVICES:\n",
    "\n",
    "#for service in grafana harvest influx telegraf ansible nodered\n",
    "for service in grafana influx telegraf #harvest #ansible nodered\n",
    "    do\n",
    "        ${service}_status\n",
    "    done\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "ticket()\n",
    "{\n",
    "\n",
    "# Send info to NodeRed when service is down:\n",
    "EPOCHNOW=`date -d \"${DATE}\" +\"%s\"`\n",
    "\n",
    "    \n",
    "generate_json()    \n",
    "    c=0\n",
    "    for((i=1;i<=5;++i))\n",
    "        do\n",
    "            dat=$(tac ${service}_uptime.log | sed -n \"${i},1p\" | cut -d@ -f2) \n",
    "\n",
    "            case $dat in\n",
    "                ''|*OK) return 1 ;;\n",
    "                *)\n",
    "\n",
    "                epoch_dat=`date -d \"${dat}\" +\"%s\"`\n",
    "\n",
    "                if [ \"$(echo $EPOCHNOW-$epoch_dat|bc)\" -le \"360\"  ] # less or equal to 360 seconds AKA 6 min (5min +1min grace time due to latency)\n",
    "                    then c=$((c+1))\n",
    "    #                if [ \"$c\" == 1 ]; then echo ${service}_down_since \"$epoch_dat\"; fi\n",
    "                fi\n",
    "                                    ;;\n",
    "            esac\n",
    "        done\n",
    "\n",
    "    if [[ $c -ge 5 ]]; then echo \"PLACEHOLDER for *ticket file with paramenters edited by sed will be passed to NodeRed*\" | tee  ${service}_monitoring_ticket_`date +\\%Y\\%m\\%d\\%H\\%M\\%S`.json; else echo OK; fi\n",
    "\n",
    "    # static IDs; variables to NodeRed via json: https://atc.bmwgroup.net/confluence/download/attachments/2076532016/InterfaceContract_EventMgmt_NAS_final.pdf?version=2&modificationDate=1646741380958&api=v2\n",
    "\n",
    "    \n",
    "for service in grafana influx telegraf #harvest #ansible nodered\n",
    "    do\n",
    "        generate_json(${service})\n",
    "    done    \n",
    "    \n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "manage_logs()\n",
    "{\n",
    "\n",
    "# PAST INCIDENTS:\n",
    "    # either use pwless ssh; or copy files to telegraf via Ansible playbook\n",
    "\n",
    "#rm incidents_*.csv 2>/dev/null\n",
    "\n",
    "for T in DAYS WEEKS MONTH;\n",
    "    do declare t=${T,,}; #echo $t;\n",
    "        RANGE=$(date -d \"$date -1 ${t}\" +\"%s\");\n",
    "\n",
    "        #cat telegraf_uptime.log | while read line;\n",
    "        ls *_uptime.log | xargs cat | sort -u | while read line;\n",
    "\n",
    "        do\n",
    "\n",
    "            x=$(echo $line |grep -v OK |cut -d@ -f2)\n",
    "            # if x is number number then convert to epoch format (y):\n",
    "            #if [[ $x == ?(-)+([0-9])  ]]; then  # x is NOT a number because \"/\" characters in time format!\n",
    "            if ! [[ $x == ''  ]]; then\n",
    "                y=$(date -d \"$x\" +\"%s\")  # && echo $y-$RANGE|bc;  # check difference\n",
    "                if [ \"$RANGE\" -le \"$y\" ]; then  echo $line >> incidents_${t}.csv; fi\n",
    "            fi\n",
    "        done\n",
    "\n",
    "    done\n",
    "\n",
    "# add when it was restarted started//since when it is running, and how long it runs; was down\n",
    "# can calculate uptime from last difference\n",
    "\n",
    "mv incidents_days.csv today.csv 2>/dev/null\n",
    "mv incidents_weeks.csv weekly.csv 2>/dev/null\n",
    "mv incidents_month.csv montly.csv 2>/dev/null\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "services_check\n",
    "ticket\n",
    "manage_logs  # Past incidents tab; logrotation to be added\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit the crontab via:\n",
    "crontab -e\n",
    "# paste the following (this script runs every minute):\n",
    "*/1 * * * * source ~/.bashrc; /home/qq_XX/monitoring_services.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2022.08.05: STATUS for P1: `70% #progress`\n",
    "\n",
    "### P1 (pending items):\n",
    "\n",
    "> Check/debug: <b>monitoring_services.sh</b> `[3%]`: generate_report() --json part; <b>UI</b>: infra.html `[2%]` #effort\n",
    "\n",
    "> 'Past Incidents' tab: add uptime `[5%]`\n",
    "\n",
    "> Enable passwordless ssh for qq user; or copy required files ('systemctl status harvest' output; maintenance.csv [resource,service,start,end] from NodeRed to telegraf host) `[5%]`\n",
    "\n",
    "> Maintenance mode `[10%]`\n",
    "\n",
    "#### P2 plan:\n",
    "- Ansible jobs \n",
    "- Performance metrics/alerts/jobs...\n",
    "- Add http<mark>s</mark> & cert to flask\n",
    "\n",
    "#### P3 plan:\n",
    "- CSS formatting\n",
    "- Check redundant packages at <mark>requirements</mark> & check which modules are being used, so that on prod we don't have to install anaconda (minimalistic approach)\n",
    "- Configure <mark>X11</mark> for jupyter on telegraf host"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decommission:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rm -rf ~/anaconda3  # also remove anaconda stuff from ~/.bashrc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tool configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Telegraf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Info from Florian:\n",
    "---\n",
    "```\n",
    "I prepared the Grid configuration already, so that the Telegraf can start to collect the data. \n",
    "Please take care that it can take up to 15 minutes with the initial data collection till it get reflected into the InfluxDB with the “prometheus” _measurements. \n",
    "\n",
    "StorageGRID requires a certificate authentication, so in addition I attached you the required certificates. \n",
    "Move them in the /etc/telegraf directory or subdirectory (modify tls_ca/tls_ca_cert & tls_key path in this case).\n",
    "\n",
    "There are 3 configuration parts to be modified / checked. \n",
    "\n",
    "#1  modify the common Telegraf config (at the beginning of the config file)\n",
    "[agent]\n",
    "   interval = “60s”\n",
    "   metric_batch_size = 5000\n",
    "   metric_buffer_limit = 75000\n",
    "\n",
    "\n",
    "#2  add the Storagegrid Input config\n",
    " [[inputs.prometheus]] \n",
    "   urls = ['https://10.2.62.68:9091/federate?match%5B%5D=%7Bjob%3D~%22.%2B%22%7D']\n",
    "   metric_version = 2\n",
    "   tls_ca = \"/etc/telegraf/cacert.pem\"\n",
    "   tls_cert = \"/etc/telegraf/cert.pem\"\n",
    "   tls_key = \"/etc/telegraf/key.pem\"\n",
    "   insecure_skip_verify = true\n",
    "   response_timeout = \"59s\"\n",
    "\n",
    "\n",
    "#3 check your [outputs.influxdb_v2]] configuration. \n",
    "Telegraf will write the data into the according bucket you set here. \n",
    "\n",
    "\n",
    "After this restart the Telegraf (via cmd # sudo systemctl stop telegraf & # sudo systemctl start telegraf). \n",
    "15 Minutes after this, the InfluxDB will reflect the StorageGRID data.\n",
    "``` \n",
    "\n",
    "> Source: mail @Fri 22/05/13 13:11\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UAT Telegraf config steps\n",
    "Telegraf configuration\n",
    "Telegraf agents located on: <b>ITAHDNASUATTEL</b>\n",
    "There is 5 instance running\n",
    "- SNMP trap receiver\n",
    "- SNMP query for Cisco Switches\n",
    "- VM server data receiver\n",
    "installation folder:\n",
    "`/etc/telegraf`\n",
    "each telegraf has its own service\n",
    "#### sytemctl status telegraf_broadcom.service\n",
    "`/usr/bin/telegraf -config /etc/telegraf/telegraf_broadcom.conf -config-directory /etc/telegraf/telegraf_broadcom`\n",
    "#### sytemctl status telegraf_cisco.service\n",
    "`/usr/bin/telegraf -config /etc/telegraf/telegraf_cisco.conf -config-directory /etc/telegraf/telegraf_cisco`\n",
    "#### sytemctl status telegraf_storage.service \n",
    "`/usr/bin/telegraf -config /etc/telegraf/telegraf_storage.conf -config-directory /etc/telegraf/telegraf_storage`\n",
    "#### sytemctl status telegraf_traps.service\n",
    "`/usr/bin/telegraf -config /etc/telegraf/telegraf_traps.conf -config-directory /etc/telegraf/telegraf_traps`\n",
    "#### sytemctl status telegraf_system.service\n",
    "`/usr/bin/telegraf -config /etc/telegraf/telegraf_system.conf -config-directory /etc/telegraf/telegraf_system`\n",
    "\n",
    "To receive SNMP traps from AIQ UM two MIB file required to copied to the configured path where the MIB's name are important\n",
    "- NETAPP.MIB\n",
    "- OCUM.MIB (this is a renamed aiqum_9.9.mib)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Influx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Influx CLI and Modify <mark>bucket's retention</mark>\n",
    "Install Influx CLI/Modify bucket's retention:\n",
    "Download package from the following URL: https://docs.influxdata.com/influxdb/cloud/tools/influx-cli/?t=Windows\n",
    "Install CLI to VDI: Because we haven't permission on the 'C:\\Program Files' folder, need modify the original command:\n",
    "Ori: Expand-Archive .\\influxdb2-client-2.3.0-windows-amd64.zip -DestinationPath 'C:\\Program Files\\InfluxData' mv 'C:\\Program Files\\InfluxData\\influxdb2-client-2.3.0-windows-amd64' 'C:\\Program Files\\InfluxData\\influx'\n",
    "Modified: Expand-Archive .\\influxdb2-client-2.3.0-windows-amd64.zip -DestinationPath 'C:\\InfluxData' mv 'C:\\InfluxData\\influxdb2-client-2.3.0-windows-amd64' 'C:\\InfluxData\\influx'\n",
    "Use Powershell for the following\n",
    "Before issuing the above command, navigate to the folder where you downloaded the CLI package. For example:\n",
    "```\n",
    "cd C:\\Users\"USERNAME\"\\Downloads`\n",
    "mkdir C:\\InfluxData`\n",
    "Expand-Archive .\\influxdb2-client-2.3.0-windows-amd64.zip -DestinationPath 'C:\\InfluxData'\n",
    "mv 'C:\\InfluxData\\influxdb2-client-2.3.0-windows-amd64' 'C:\\InfluxData\\influx'\n",
    "Navigate to the C:\\InfluxData\\influx // because we cannot modify the 'path' variable, need to go to the folder where the influx.exe exists\n",
    "Create an influx CLI's config for the remote host: .\\influx config create -a -n CONFIGNAME -u URL -t TOKEN_WHICH_HAS_PROPER_PRIVILEGES -o ORGANIZATION\n",
    "List bucket's current settings:\n",
    "PS C:\\InfluxData\\influx> .\\influx.exe bucket list ID Name Retention Shard group duration Organization ID Schema Type 834ba3f797c35789 BroadcomBES 1440h0m0s 24h0m0s f24c8a8d0e5f36e8 implicit f827bf73e326118b CiscoBackend 1440h0m0s 24h0m0s f24c8a8d0e5f36e8 implicit\n",
    "Modify bucket's retention: Command reference: https://docs.influxdata.com/influxdb/v2.2/organizations/buckets/update-bucket/\n",
    ".\\influx bucket update -i BUCKET_ID -r NEW_RETENTION_TIME\n",
    "```\n",
    "Done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "8678b89255859bba6a2fda3170875bff35eb43e847a261467ed8f377912a0ea8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
